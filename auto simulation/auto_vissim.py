import sys
import os
import re
import time
import random
import shutil
import pyodbc
import fnmatch
import datetime
import pythoncom
import pywintypes
import pandas as pd
import win32com.client as com
from win32com.client import gencache

from decimal import Decimal
from dotenv import load_dotenv
from contextlib import redirect_stdout









def set_dpi_awareness():
    try:
        from ctypes import windll
        windll.shcore.SetProcessDpiAwareness(1)
    except ImportError:
        print("ctypes ëª¨ë“ˆì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Python í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”.")
    except AttributeError:
        print("SetProcessDpiAwareness í•¨ìˆ˜ê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” í™˜ê²½ì…ë‹ˆë‹¤. Windows 8.1 ì´ìƒì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.")
    except OSError as os_error:
        print(f"OS ê´€ë ¨ ì˜¤ë¥˜ ë°œìƒ: {os_error}")
    except Exception as e:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
set_dpi_awareness()
sys.path.append(os.path.dirname(os.path.abspath(__file__)))









# ============================================================================ [ í˜„ì¬ ì¼ì‹œ ì„¤ì • ë° ì „ë‚  ì‹œê°„ ê³„ì‚° ]

# í˜„ì¬ ì‹œê°„ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ë¶€ë¶„
current_datetime = datetime.datetime.now()

# >> ì•„ë˜ ë³€ìˆ˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìˆ˜ë™ìœ¼ë¡œ í˜„ì¬ì‹œê°„ì„ ì§€ì •í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. í˜„ì¬ ì‹œê°ì„ ìˆ˜ë™ ì§€ì •í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
current_datetime = datetime.datetime.strptime("2025090201", "%Y%m%d%H")

# ì „ë‚  ë‚ ì§œ ê³„ì‚°
target_date = (current_datetime - datetime.timedelta(days=1)).strftime("%Y%m%d")
peak_hours = ['08', '11', '14', '17']
target_stat_hours = [f"{target_date}{hour}" for hour in peak_hours]  # ["2025070108", "2025070111", "2025070114", "2025070117"]

# ì¡°íšŒëœ ë°ì´í„°ë¥¼ ë‹´ì„ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
traffic_data_08 = []
traffic_data_11 = []
traffic_data_14 = []
traffic_data_17 = []









# ============================================================================ [ ì „ì—­ìƒíƒœì„¤ì • - DBì ‘ì†ì •ë³´ & ë„¤íŠ¸ì›Œí¬ ]

class Config:
    
    def __init__(self):
        load_dotenv(dotenv_path="C:/Digital Twin Simulation Program/.env")
        self.env = os.getenv("FLASK_ENV", "production")
        
        self.db_config = {
            "test": {
                "driver": "Tibero 5 ODBC Driver",
                "server": os.getenv("ENZERO_SERVER"),
                "port": os.getenv("ENZERO_PORT"),
                "db": os.getenv("ENZERO_DB"),
                "uid": os.getenv("ENZERO_UID"),
                "pwd": os.getenv("ENZERO_PWD")
            },
            "prod": {
                "dsn": os.getenv("DSNNAME"),
                "uid": os.getenv("DBUSER"),
                "pwd": os.getenv("DBPWD")
            }
        }

        self.vissim_paths = self._load_vissim_paths()

    # ê²½í¬, ì†¡ì •ë™, ë„ì‹¬, êµë™ ë„¤íŠ¸ì›Œí¬ ê²½ë¡œ
    
    def _load_vissim_paths(self):
        base_path = r"C:\Digital Twin Simulation Network\VISSIM"
        file_list = [
            "gyeongpo.inpx",
            "songjung.inpx",
            "downtown.inpx",
            "gyodong.inpx"
        ]
        return {
            os.path.splitext(name)[0]: os.path.join(base_path, name)
            for name in file_list
        }

# ============================================================================ [ DB ì—°ê²° - êµí†µëŸ‰ ì¡°íšŒ ]

class DatabaseManager:
    
    def __init__(self, config: Config):
        self.config = config
        self.conn = self._connect()
        self.cursor = self.conn.cursor() if self.conn else None
        self.columns = [
            "STAT_HOUR", "CROSS_ID", "INFRA_TYPE", "SPECIALDAY", "VPHG", "VPHG", "VS", "LOS",
            "VOL_01", "VOL_02", "VOL_03", "VOL_04", "VOL_05", "VOL_06", "VOL_07", "VOL_08", "VOL_09",
            "VOL_10", "VOL_11", "VOL_12", "VOL_13", "VOL_14", "VOL_15", "VOL_16", "VOL_17", "VOL_18",
            "VOL_19", "VOL_20", "VOL_21", "VOL_22", "VOL_23",
            "WALKER_CNT", "CRASH_CNT", "DELAY_TIME"
        ]
        self.traffic_data_by_hour = {
            "08": [],
            "11": [],
            "14": [],
            "17": []
        }

    def _connect(self):
        try:
            if self.config.env == "test":
                db = self.config.db_config["test"]
                print(">>>>> âœ… ì—”ì œë¡œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°")
                return pyodbc.connect(
                    f"DRIVER={db['driver']};"
                    f"SERVER={db['server']};"
                    f"PORT={db['port']};"
                    f"DB={db['db']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
            else:
                db = self.config.db_config["prod"]
                print(">>>>> âœ… ê°•ë¦‰ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°")
                return pyodbc.connect(
                    f"DSN={db['dsn']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
        except Exception as e:
            print("â›” DB ì—°ê²° ì‹¤íŒ¨:", e)
            return None

    def fetch_peak_traffic_data(self):
        try:
            def convert_row_to_dict(row, columns):
                return {
                    col: float(val) if isinstance(val, Decimal) else val
                    for col, val in zip(columns, row)
                }

            if not self.cursor:
                print(">>> DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return

            formatted_hours = "', '".join(target_stat_hours)
            query = f"""
                SELECT *
                FROM TOMMS.STAT_HOUR_CROSS
                WHERE STAT_HOUR IN ('{formatted_hours}')
                AND INFRA_TYPE = 'SMT'
            """
            self.cursor.execute(query)
            rows = self.cursor.fetchall()
            data_dicts = [convert_row_to_dict(row, self.columns) for row in rows]

            # ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ ì €ì¥
            for row in data_dicts:
                stat_hour = row["STAT_HOUR"]
                suffix = stat_hour[-2:]
                if suffix in self.traffic_data_by_hour:
                    self.traffic_data_by_hour[suffix].append(row)

            print(f"âœ… [ êµí†µëŸ‰ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ ] - ì´ {len(data_dicts)}ê±´")
            for hour in ["08", "11", "14", "17"]:
                print(f"âœ… ì‹œê°„ëŒ€ {hour}: {len(self.traffic_data_by_hour[hour])}ê±´")
                # âœ… ì‹œê°„ëŒ€ 08: 96ê±´
                # âœ… ì‹œê°„ëŒ€ 11: 96ê±´
                # âœ… ì‹œê°„ëŒ€ 14: 96ê±´
                # âœ… ì‹œê°„ëŒ€ 17: 96ê±´

        except Exception as e:
            print("â›” êµí†µëŸ‰ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜:", e)

# ============================================================================ [ DB ì—°ê²° - êµì°¨ë¡œ ë°©í–¥ë³„ movement ì¡°íšŒ ]

class NodeDirectionManager:

    def __init__(self, config: Config):
        self.config = config
        self.conn = self._connect()
        self.cursor = self.conn.cursor() if self.conn else None

    def _connect(self):
        try:
            if self.config.env == "test":
                db = self.config.db_config["test"]
                return pyodbc.connect(
                    f"DRIVER={db['driver']};"
                    f"SERVER={db['server']};"
                    f"PORT={db['port']};"
                    f"DB={db['db']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
            else:
                db = self.config.db_config["prod"]
                return pyodbc.connect(
                    f"DSN={db['dsn']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
        except Exception as e:
            print("â›” DB ì—°ê²° ì‹¤íŒ¨:", e)
            return None

    def fetch_node_dir_info(self):
        if not self.cursor:
            print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        try:
            query = """
                SELECT CROSS_ID, NODE_NAME, APPR_ID, MOVEMENT, DIRECTION
                FROM TOMMS.NODE_DIR_INFO
            """
            self.cursor.execute(query)
            rows = self.cursor.fetchall()

            cleaned_rows = []
            for row in rows:
                cleaned_row = []
                for val in row:
                    if isinstance(val, Decimal):
                        cleaned_row.append(int(val))
                    else:
                        cleaned_row.append(val)
                cleaned_rows.append(tuple(cleaned_row))

            df = pd.DataFrame(cleaned_rows, columns=["CROSS_ID", "NODE_NAME", "APPR_ID", "MOVEMENT", "DIRECTION"])
            
            print(f"âœ… NODE_DIR_INFO ì¡°íšŒ ì™„ë£Œ - {len(df)}ê±´")
            return df

        except Exception as e:
            print("â›” NODE_DIR_INFO ì¡°íšŒ ì‹¤íŒ¨:", e)
            return pd.DataFrame()

# ============================================================================ [ DB ì—°ê²° - êµ¬ê°„ ì •ë³´ ì¡°íšŒ ]

class VTTMInfoManager:

    def __init__(self, config: Config):
        self.config = config
        self.conn = self._connect()
        self.cursor = self.conn.cursor() if self.conn else None

    def _connect(self):
        try:
            if self.config.env == "test":
                db = self.config.db_config["test"]
                return pyodbc.connect(
                    f"DRIVER={db['driver']};"
                    f"SERVER={db['server']};"
                    f"PORT={db['port']};"
                    f"DB={db['db']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
            else:
                db = self.config.db_config["prod"]
                return pyodbc.connect(
                    f"DSN={db['dsn']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
        except Exception as e:
            print("â›” DB ì—°ê²° ì‹¤íŒ¨:", e)
            return None

    def fetch_vttm_info(self):
        if not self.cursor:
            print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        try:
            query = """
                SELECT VTTM_ID, FROM_NODE_NAME, TO_NODE_NAME
                FROM TOMMS.VTTM_INFO
            """
            self.cursor.execute(query)
            rows = self.cursor.fetchall()

            cleaned_rows = []
            for row in rows:
                cleaned_row = []
                for val in row:
                    if isinstance(val, Decimal):
                        cleaned_row.append(int(val))
                    else:
                        cleaned_row.append(val)
                cleaned_rows.append(tuple(cleaned_row))

            df = pd.DataFrame(cleaned_rows, columns=["VTTM_ID", "FROM_NODE_NAME", "TO_NODE_NAME"])
            print(f"âœ… VTTM_INFO ì¡°íšŒ ì™„ë£Œ - {len(df)}ê±´")
            return df

        except Exception as e:
            print("â›” VTTM_INFO ì¡°íšŒ ì‹¤íŒ¨:", e)
            return pd.DataFrame()









# ============================================================================ [ êµ¬ê°„ ê²°ê³¼ê°’ DB INSERT ]

def insert_vttm_results_to_db(df_vttm, db_manager):
    
    if db_manager.cursor is None:
        print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    insert_query = """
        INSERT INTO VTTM_RESULT (
            STAT_HOUR, VTTM_ID, DISTANCE, VEHS, TRAVEL_TIME
        ) VALUES (?, ?, ?, ?, ?)
    """

    # NaNì„ Noneìœ¼ë¡œ ëŒ€ì²´, íƒ€ì… í˜•ë³€í™˜
    def clean_value(val, target_type):
        if pd.isna(val):
            return None
        try:
            if target_type == "int":
                return int(val)
            elif target_type == "float":
                return float(val)
            elif target_type == "str":
                return str(val)
        except:
            return None

    insert_data = []
    for _, row in df_vttm.iterrows():
        insert_data.append((
            clean_value(row.get("STAT_HOUR"), "str"),
            clean_value(row.get("VTTM_ID"), "str"),
            clean_value(row.get("DISTANCE"), "float"),
            clean_value(row.get("VEHS"), "int"),
            clean_value(row.get("TRAVEL_TIME"), "float")
        ))

    try:
        db_manager.cursor.executemany(insert_query, insert_data)
        db_manager.conn.commit()
        print(f"âœ… VTTM_RESULTì— {len(insert_data)}ê±´ ì‚½ì… ì™„ë£Œ")
    except Exception as e:
        print("â›” DB ì‚½ì… ì¤‘ ì˜¤ë¥˜:", e)
        db_manager.conn.rollback()

# ============================================================================ [ êµì°¨ë¡œ ê²°ê³¼ê°’ DB INSERT ]

def insert_node_results_to_db(df_node: pd.DataFrame, db_manager):
    
    if db_manager.cursor is None:
        print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    insert_query = """
        INSERT INTO NODE_RESULT (
            STAT_HOUR, TIMEINT, NODE_ID, QLEN, VEHS, DELAY, STOPS
        ) VALUES (?, ?, ?, ?, ?, ?, ?)
    """

    def clean_value(val, target_type):
        if pd.isna(val):
            return None
        try:
            if target_type == "int":
                return int(val)
            elif target_type == "float":
                return float(val)
            elif target_type == "str":
                return str(val)
        except:
            return None

    insert_data = []
    for _, row in df_node.iterrows():
        insert_data.append((
            clean_value(row.get("STAT_HOUR"), "str"),
            clean_value(row.get("TIMEINT"), "str"),
            clean_value(row.get("NODE_ID"), "str"),
            clean_value(row.get("QLEN"), "float"),
            clean_value(row.get("VEHS"), "int"),
            clean_value(row.get("DELAY"), "float"),
            clean_value(row.get("STOPS"), "float")
        ))

    try:
        db_manager.cursor.executemany(insert_query, insert_data)
        db_manager.conn.commit()
        print(f"âœ… NODE_RESULTì— {len(insert_data)}ê±´ ì‚½ì… ì™„ë£Œ")
    except Exception as e:
        print("â›” NODE_RESULT ì‚½ì… ì˜¤ë¥˜:", e)
        db_manager.conn.rollback()

# ============================================================================ [ êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ DB INSERT ]

def insert_node_dir_results_to_db(df_dir_node: pd.DataFrame, db_manager):
    
    if db_manager.cursor is None:
        print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    insert_query = """
        INSERT INTO NODE_DIR_RESULT (
            STAT_HOUR, TIMEINT, NODE_ID, SA_NO, APPR_ID, DIRECTION, QLEN, VEHS, DELAY, STOPS
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """

    def clean_value(val, target_type):
        if pd.isna(val):
            return None
        try:
            if target_type == "int":
                return int(val)
            elif target_type == "float":
                return float(val)
            elif target_type == "str":
                return str(val)
        except:
            return None

    insert_data = []
    for _, row in df_dir_node.iterrows():
        insert_data.append((
            clean_value(row.get("STAT_HOUR"), "str"),
            clean_value(row.get("TIMEINT"), "str"),
            clean_value(row.get("NODE_ID"), "str"),
            clean_value(row.get("SA_NO"), "str"),
            clean_value(row.get("APPR_ID"), "int"),
            clean_value(row.get("DIRECTION"), "int"),
            clean_value(row.get("QLEN"), "float"),
            clean_value(row.get("VEHS"), "int"),
            clean_value(row.get("DELAY"), "float"),
            clean_value(row.get("STOPS"), "float")
        ))

    try:
        db_manager.cursor.executemany(insert_query, insert_data)
        db_manager.conn.commit()
        print(f"âœ… NODE_DIR_RESULTì— {len(insert_data)}ê±´ ì‚½ì… ì™„ë£Œ")
    except Exception as e:
        print("â›” NODE_DIR_RESULT ì‚½ì… ì˜¤ë¥˜:", e)
        db_manager.conn.rollback()

# ============================================================================ [ Data Collection ê²°ê³¼ê°’ DB INSERT ]

def insert_dc_to_db(dc: pd.DataFrame, db_manager):
    
    if db_manager.cursor is None:
        print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    insert_query = """
            INSERT INTO DC_RESULT (
            DISTRICT, STAT_HOUR, DC_ID, DISTANCE, VEHS, SPEED
            ) VALUES (?, ?, ?, ?, ?, ?)
    """
    
    def clean_value(val, target_type):
        if pd.isna(val):
            return None
        try:
            if target_type == "int":
                return int(val)
            elif target_type == "float":
                return float(val)
            elif target_type == "str":
                return str(val)
        except:
            return None
    
    insert_data = []
    for _, row in dc.iterrows():
        insert_data.append((
            clean_value(row.get("DISTRICT"), "int"),
            clean_value(row.get("STAT_HOUR"), "str"),
            clean_value(row.get("DC_ID"), "int"),
            clean_value(row.get("DISTANCE"), "float"),
            clean_value(row.get("VEHS"), "int"),
            clean_value(row.get("SPEED"), "float")
        ))

    try:
        db_manager.cursor.executemany(insert_query, insert_data)
        db_manager.conn.commit()
        print(f"âœ… DC_RESULTì— {len(insert_data)}ê±´ ì‚½ì… ì™„ë£Œ")
    except Exception as e:
        print("â›” DC_RESULT ì‚½ì… ì˜¤ë¥˜:", e)
        db_manager.conn.rollback()

# ============================================================================ [ Network Performance ê²°ê³¼ê°’ DB INSERT ]

def insert_np_to_db(np: pd.DataFrame, db_manager):
    
    if db_manager.cursor is None:
        print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    insert_query = """
            INSERT INTO NP_RESULT (
            DISTRICT, STAT_HOUR, VEHS, COST
            ) VALUES (?, ?, ?, ?)
    """
    
    def clean_value(val, target_type):
        if pd.isna(val):
            return None
        try:
            if target_type == "int":
                return int(val)
            elif target_type == "float":
                return float(val)
            elif target_type == "str":
                return str(val)
        except:
            return None
    
    insert_data = []
    for _, row in np.iterrows():
        insert_data.append((
            clean_value(row.get("DISTRICT"), "int"),
            clean_value(row.get("STAT_HOUR"), "str"),
            clean_value(row.get("VEHS"), "int"),
            clean_value(row.get("COST"), "float")
        ))

    try:
        db_manager.cursor.executemany(insert_query, insert_data)
        db_manager.conn.commit()
        print(f"âœ… NP_RESULTì— {len(insert_data)}ê±´ ì‚½ì… ì™„ë£Œ")
    except Exception as e:
        print("â›” NP_RESULT ì‚½ì… ì˜¤ë¥˜:", e)
        db_manager.conn.rollback()






# ============================================================================ [ ì‹œë®¬ë ˆì´ì…˜ ì»¨íŠ¸ë¡¤ëŸ¬ ]

class VissimSimulationManager:
    
    def __init__(self, config: Config, db_manager: DatabaseManager):
        self.vissim = None
        self.paths = config.vissim_paths
        self.db = db_manager
        self._com_initialized = False
    
    # --- VISSIM COM ê°ì²´ë¥¼ "ì„±ê³µí•  ë•Œê¹Œì§€" ìƒì„±í•˜ëŠ” ìœ í‹¸
    
    def _init_com(self):
        """STAë¡œ COM ì´ˆê¸°í™” (ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œí•´ë„ ì•ˆì „í•˜ë„ë¡ ê°€ë“œ)"""
        if not self._com_initialized:
            # COINIT_APARTMENTTHREADED = STA
            pythoncom.CoInitializeEx(pythoncom.COINIT_APARTMENTTHREADED)
            self._com_initialized = True
            print("ğŸ”§ COM initialized (STA)")

    def _uninit_com(self):
        """COM í•´ì œ (ì°¸ì¡° ì¹´ìš´íŠ¸ ë§ì¶”ê¸°)"""
        if self._com_initialized:
            pythoncom.CoUninitialize()
            self._com_initialized = False
            print("ğŸ§¹ COM uninitialized")
    
    def _ensure_vissim(self,
                       prog_ids=("Vissim.Vissim.22",),
                       max_attempts=8,
                       base_delay=1.5,
                       hard_timeout_sec=90) -> bool:
        self._init_com()
        start = time.time()
        last_err = None

        for attempt in range(1, max_attempts + 1):
            if time.time() - start > hard_timeout_sec:
                print(f"â›” í•˜ë“œ íƒ€ì„ì•„ì›ƒ ì´ˆê³¼({hard_timeout_sec}s)")
                break

            for prog in prog_ids:
                try:
                    # 1) Dispatch
                    self.vissim = com.Dispatch(prog)
                    print(f"ğŸ”µ VISSIM COM ìƒì„± ì„±ê³µ: {prog} (attempt={attempt})")
                    return True
                except pywintypes.com_error as e1:
                    last_err = e1
                    # 2) EnsureDispatch í´ë°±
                    try:
                        self.vissim = gencache.EnsureDispatch(prog)
                        print(f"ğŸ”µ VISSIM COM ìƒì„± ì„±ê³µ(EnsureDispatch): {prog} (attempt={attempt})")
                        return True
                    except Exception as e2:
                        last_err = e2

            sleep_s = min(base_delay * (2 ** (attempt - 1)), 10.0) + random.uniform(0.0, 0.5)
            print(f"ğŸ” ì¬ì‹œë„ ëŒ€ê¸°: {sleep_s:.1f}s (attempt={attempt}/{max_attempts})")
            time.sleep(sleep_s)

        print(f"â›” ìµœì¢… ì‹¤íŒ¨: {repr(last_err)}")
        self.vissim = None
        return False

    # ============================================================================ [ ì—°ê³„ - ì‹¤í–‰ - ì¶”ì¶œ - ì €ì¥ - ì¢…ë£Œ ]

    def run_full_simulation(self, area):
        global target_stat_hours

        print(f"ğŸ”µ vissim ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ê±´ë„¤ë°›ì€ ë¶„ì„ëŒ€ìƒ ì¼ì‹œ : {target_date}")
        print(f"ğŸ”µ vissim ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ê±´ë„¤ë°›ì€ ë¶„ì„ëŒ€ìƒ ì§€êµ¬ : {area}")
        path = self.paths.get(area)

        if not path or not os.path.isfile(path):
            print(f"â›” [ ê²½ê³  ] {area} íŒŒì¼ ì—†ìŒ: {path}")
            return

        # âœ… ë°˜ë“œì‹œ ìƒì„±ë  ë•Œê¹Œì§€ ì‹œë„
        if not self._ensure_vissim(prog_ids=("Vissim.Vissim.22",), max_attempts=8, base_delay=1.5, hard_timeout_sec=90):
            print("â›” VISSIM ê°ì²´ë¥¼ ìƒì„±í•˜ì§€ ëª»í•´ ì‹œë®¬ë ˆì´ì…˜ ìŠ¤í‚µ")
            self._uninit_com()
            return

        try:
            # ------------------------------------------------------------ ë°˜ë³µëœ ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„
            for idx, (hour_key, traffic_list) in enumerate(self.db.traffic_data_by_hour.items()):
                try:
                    idx = peak_hours.index(hour_key)
                    full_stat_hour = target_stat_hours[idx]
                except ValueError:
                    print(f"â›” [ ì˜¤ë¥˜ ] ì‹œê°„ëŒ€ {hour_key}ëŠ” peak_hoursì— ì—†ìŠµë‹ˆë‹¤.")
                    continue

                print(f"ğŸ”µ [ {area} ] ( {full_stat_hour} ) ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ===")

                # [1] ì´ì „ ê²°ê³¼ ì‚­ì œ
                self.cleanup_att_files(area)

                # [2] ë„¤íŠ¸ì›Œí¬ íŒŒì¼ ë‹¤ì‹œ ë¡œë“œ (ìµœëŒ€ 3íšŒ ì†Œí”„íŠ¸ ì¬ì‹œë„)
                for load_try in range(1, 4):
                    try:
                        self.vissim.LoadNet(path, False)
                        print(f"ğŸ” [ ë„¤íŠ¸ì›Œí¬ ì¬ë¡œë“œ ì™„ë£Œ ] {area} â†’ {path} (try={load_try})")
                        break
                    except pywintypes.com_error as e:
                        print(f"âš ï¸ ì¬ë¡œë“œ ì‹¤íŒ¨(try={load_try}): {repr(e)}")
                        time.sleep(1.0 * load_try)
                else:
                    print(f"â›” [ ì˜¤ë¥˜ ] ë„¤íŠ¸ì›Œí¬ ì¬ë¡œë“œ ë°˜ë³µ ì‹¤íŒ¨: {path}")
                    continue

                # [3] ì—°ê³„ â†’ ì‹¤í–‰ â†’ ì¶”ì¶œ
                self.apply_traffic_data(traffic_list)
                self.run_simulation()
                df_node, df_dir_node, df_vttm, dc, np = self.extract_results(stat_hour=full_stat_hour, area_name=area)

                # [5] DB ì €ì¥
                self.save_results((df_dir_node, df_node, df_vttm, dc, np), area, hour_key)

                # [6] ê²°ê³¼ íŒŒì¼ ì‚­ì œ
                self.cleanup_att_files(area)
                
        finally:
            # ------------------------------------------------------------ ì¢…ë£Œ
            self.close_simulation()
            self._uninit_com()  # âœ… COM í•´ì œ

    # ============================================================================ [ ì—°ê³„ - vehicle input / static route ]

    def apply_traffic_data(self, traffic_list):
        
        print(f"ğŸ”µ [ êµí†µëŸ‰ ì…ë ¥ ì‹œì‘ ] ì´ {len(traffic_list)}ê±´")

        for idx, row in enumerate(traffic_list, 1):
            stat_hour = row.get("STAT_HOUR")
            cross_id = row.get("CROSS_ID")

            # VOL_xx ì¤‘ Noneì´ ì•„ë‹Œ ê°’ë§Œ ì¶”ì¶œ
            volume_data = {
                key.replace("VOL_", ""): int(value)
                for key, value in row.items()
                if key.startswith("VOL_") and value is not None
            }

            # ------------------------------------------------------------ [ vehicle input êµí†µëŸ‰ ì…ë ¥ ]
            
            num_decisions = self.vissim.Net.VehicleRoutingDecisionsStatic.count
            vehicle_input_nos = self.vissim.Net.VehicleInputs.GetMultiAttValues('No')
            vehicle_input_node_ids = self.vissim.Net.VehicleInputs.GetMultiAttValues('Node_ID')
            vehicle_input_link_ids = self.vissim.Net.VehicleInputs.GetMultiAttValues('Link_ID')
            
            grouped_data_list = []

            for no, node_id, link_id in zip(vehicle_input_nos, vehicle_input_node_ids, vehicle_input_link_ids):
                if node_id[1] is None or link_id[1] is None:  # node_idì™€ link_idì— Noneì´ ìˆìœ¼ë©´ ì œì™¸
                    continue

                # CROSS_IDì™€ node_idê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if str(cross_id) != str(node_id[1]):
                    continue

                # VOL_xxì—ì„œ xx == link_id
                vol_key = f"{int(link_id[1]):02d}"  # ì˜ˆ: 4 â†’ "04"
                vi_vol = volume_data.get(vol_key)

                if vi_vol is None:
                    continue  # í•´ë‹¹ ë°©í–¥ ë°ì´í„° ì—†ìŒ

                # print(f"[ Vehicle Input ] (InputNo = {no[1]}) (NodeID = {node_id[1]}) (LinkID = {link_id[1]}) (Volume = {vi_vol})")

                # êµí†µëŸ‰ ì…ë ¥
                vi = self.vissim.Net.VehicleInputs.ItemByKey(no[1])
                vi.SetAttValue('Volume(1)', vi_vol)
                vi.SetAttValue('Volume(2)', vi_vol)
                vi.SetAttValue('Volume(3)', vi_vol)
                vi.SetAttValue('Volume(4)', vi_vol)
                vi.SetAttValue('Volume(5)', vi_vol)
            
            # ------------------------------------------------------------ [ static route êµí†µëŸ‰ ì…ë ¥ ]
            
            vrds = self.vissim.Net.VehicleRoutingDecisionsStatic
            num_decisions = self.vissim.Net.VehicleRoutingDecisionsStatic.Count
            
            for i in range(1, num_decisions + 1):
                if vrds.ItemKeyExists(i):
                    decision = vrds.ItemByKey(i)

                    for route in decision.VehRoutSta.GetAll():
                        sr_node_id = route.AttValue('VehRoutDec\\Node_ID')
                        sr_turn_id = route.AttValue('Turn_ID')
                        
                        # ì¡°ê±´: ë‘˜ ë‹¤ Noneì´ ì•„ë‹ˆì–´ì•¼ í•¨
                        if sr_node_id is None or sr_turn_id is None:
                            continue

                        # CROSS_IDì™€ ë§¤ì¹­
                        if str(cross_id) != str(sr_node_id):
                            continue

                        # Turn_IDì— í•´ë‹¹í•˜ëŠ” vol key ìƒì„± â†’ ex: 3 â†’ "03"
                        vol_key = f"{int(sr_turn_id):02d}"
                        sr_vol = volume_data.get(vol_key)

                        if sr_vol is None:
                            continue  # í•´ë‹¹ ë°©í–¥ì— ëŒ€í•´ êµí†µëŸ‰ ì—†ìŒ

                        # print(f"[ Static Route ] (NodeID = {sr_node_id}) (TurnID = {sr_turn_id}) (Volume= {sr_vol})")
                        
                        route.SetAttValue("RelFlow(1)", sr_vol)
                        route.SetAttValue("RelFlow(2)", sr_vol)
                        route.SetAttValue("RelFlow(3)", sr_vol)
                        route.SetAttValue("RelFlow(4)", sr_vol)
                        route.SetAttValue("RelFlow(5)", sr_vol)

    # ============================================================================ [ ì‹¤í–‰ - simulation run ]

    def run_simulation(self):
        
        End_of_simulation = 4200
        self.vissim.Simulation.SetAttValue('SimPeriod', End_of_simulation) # ì‹œë®¬ë ˆì´ì…˜ 4200ì´ˆ
        self.vissim.Graphics.CurrentNetworkWindow.SetAttValue("QuickMode", 1)
        self.vissim.Simulation.SetAttValue('UseMaxSimSpeed', True)
        self.vissim.Simulation.RunContinuous()

    # ============================================================================ [ ì¶”ì¶œ - node results / vehicle input ]

    def extract_results(self, stat_hour: str, area_name: str):
        
        print(f"ğŸ”µ ë¶„ì„ëŒ€ìƒì¼ì‹œ [ {stat_hour} ] ë¶„ì„ëŒ€ìƒì§€ì—­ [ {area_name} ]") # 2025070108, 2025070111

        target_folder = r"C:\Digital Twin Simulation Network\VISSIM"
        results = {}

        # ------------------------------------------------------------ ì‚­ì œ ëŒ€ìƒ ì œê±° (.results, .err, .lock ë“±)
        
        for file in os.listdir(target_folder):
            full_path = os.path.join(target_folder, file)

            if file.endswith(".err") or file.endswith(".lock"):
                try:
                    os.remove(full_path)
                    print(f"âœ… [ íŒŒì¼ì‚­ì œ ì™„ë£Œ ] : {file}")
                except Exception as e:
                    print(f"â›” [ íŒŒì¼ì‚­ì œ ì‹¤íŒ¨ ]: {file} â†’ {e}")

            elif file.endswith(".results") and os.path.isdir(full_path):
                try:
                    shutil.rmtree(full_path)
                    print(f"âœ… [ í´ë”ì‚­ì œ ì™„ë£Œ ] : {file}")
                except Exception as e:
                    print(f"â›” [ í´ë”ì‚­ì œ ì‹¤íŒ¨ ]: {file} â†’ {e}")

        # ------------------------------------------------------------ íŒŒì¼ ì°¾ê¸°

        def find_latest_index(base_name, result_type):
            pattern = re.compile(rf"{re.escape(base_name)}_{re.escape(result_type)}_(\d+)\.att")
            max_idx = 0
            for file in os.listdir(target_folder):
                m = pattern.match(file)
                if m:
                    max_idx = max(max_idx, int(m.group(1)))
            return f"{max_idx:03d}" if max_idx > 0 else None

        # ------------------------------------------------------------ ê²°ê³¼ê°’ dfë¡œ í• ë‹¹í•˜ê¸°

        def read_att_file(path):
            if not os.path.exists(path):
                print(f"â›” íŒŒì¼ ì—†ìŒ: {path}")
                return pd.DataFrame()

            encodings = ["utf-8-sig", "utf-16", "cp949", "utf-8"]
            for enc in encodings:
                try:
                    with open(path, "r", encoding=enc, errors="strict") as f:
                        lines = f.read().splitlines()
                    break
                except (UnicodeDecodeError, UnicodeError):
                    continue
            else:
                print(f"â›” ì¸ì½”ë”© ì‹¤íŒ¨: {path}")
                return pd.DataFrame()

            # ë³´í†µ '$'ê°€ ë“¤ì–´ê°„ ë¼ì¸ì´ 2ë²ˆ ì´ìƒ ì¡´ì¬, ë‘ ë²ˆì§¸ê°€ í—¤ë”
            dollar_lines = [i for i, line in enumerate(lines) if "$" in line]
            if len(dollar_lines) < 2:
                print(f"â›” í¬ë§· ì´ìƒ(í—¤ë” íƒì§€ ì‹¤íŒ¨): {path}")
                return pd.DataFrame()

            header_idx = dollar_lines[1]
            header_line = lines[header_idx]

            # âœ… í•µì‹¬: '$'ë¶€í„° ì²« ':'ê¹Œì§€ ì œê±° â†’ ì–´ë–¤ í—¤ë” íƒ€ì…ì´ ì™€ë„ ë™ì‘
            # ì˜ˆ) $DATACOLLECTIONMEASUREMENTEVALUATION:SIMRUN;TIMEINT;... â†’ SIMRUN;TIMEINT;...
            header_line = re.sub(r"^\$[^:]*:", "", header_line).strip()

            columns = [c.strip() for c in header_line.split(';') if c.strip()]
            data_lines = lines[header_idx + 1:]

            # ë°ì´í„° ë¶€ë¶„ íŒŒì‹±
            rows = []
            for line in data_lines:
                if not line.strip():
                    continue
                values = [v.strip() for v in line.split(';')]
                # ì—´ ê°œìˆ˜ ë³´ì •
                if len(values) < len(columns):
                    values += [''] * (len(columns) - len(values))
                elif len(values) > len(columns):
                    values = values[:len(columns)]
                rows.append(dict(zip(columns, values)))

            df = pd.DataFrame(rows)
            return df

        # ------------------------------------------------------------ ê° êµ¬ì—­ ê²°ê³¼ê°’ ì²˜ë¦¬

        latest_index = find_latest_index(area_name, "Node Results")
        if not latest_index:
            print(f"â›” {area_name}: ì‹œë®¬ë ˆì´ì…˜ íŒŒì¼ ì—†ìŒ")
            return {}

        # íŒŒì¼ ê²½ë¡œ ì •ì˜
        node_file = os.path.join(target_folder, f"{area_name}_Node Results_{latest_index}.att")
        vttm_file = os.path.join(target_folder, f"{area_name}_Vehicle Travel Time Results_{latest_index}.att")
        dc_file = os.path.join(target_folder, f"{area_name}_Data Collection Results_{latest_index}.att")
        np_file = os.path.join(target_folder, f"{area_name}_Vehicle Network Performance Evaluation Results_{latest_index}.att")

        # íŒŒì¼ ì½ê¸°
        df_dir_node = read_att_file(node_file)
        df_vttm = read_att_file(vttm_file)
        dc = read_att_file(dc_file)
        np = read_att_file(np_file)

        print(f"âœ… {area_name} - Node Results ({df_dir_node.shape[0]}í–‰)")
        print(f"âœ… {area_name} - Travel Time Results ({df_vttm.shape[0]}í–‰)")
        print(f"âœ… {area_name} - Data Collection Results ({dc.shape[0]}í–‰)")
        print(f"âœ… {area_name} - Vehicle Network Performance Evaluation Results ({np.shape[0]}í–‰)")

        # ì»¬ëŸ¼ëª… ë§¤í•‘
        district_map = {
            "gyodong": 1,
            "songjung": 2,
            "downtown": 3,
            "gyeongpo": 4
        }
        timeint_map = {
            '600-1500': '00-15',
            '1500-2400': '15-30',
            '2400-3300': '30-45',
            '3300-4200': '45-00',
        }
        node_col_map = {
            "VEHS(ALL)": "VEHS",
            "VEHDELAY(ALL)": "DELAY",
            "STOPS(ALL)": "STOPS",
            "MOVEMENT\\NODE\\NODE_ID": "NODE_ID",
            "MOVEMENT\\NODE\\SA": "SA_NO"
        }
        vttm_col_map = {
            "VEHICLETRAVELTIMEMEASUREMENT\\NAME": "VTTM_ID",
            "VEHS(ALL)": "VEHS",
            "TRAVTM(ALL)": "TRAVEL_TIME",
            "DISTTRAV(ALL)": "DISTANCE",
            "VEHICLETRAVELTIMEMEASUREMENT\\LINKS_ID": "LINK_ID",
            "VEHICLETRAVELTIMEMEASUREMENT\\UPDOWN": "UPDOWN",
            "VEHICLETRAVELTIMEMEASUREMENT\\SA": "SA_NO",
            "VEHICLETRAVELTIMEMEASUREMENT\\ROAD_NAME": "ROAD_NAME",
            "VEHICLETRAVELTIMEMEASUREMENT\\ACTIVE": "ACTIVE"
        }
        
        data_col_map = {
            "DATACOLLECTIONMEASUREMENT": "DC_ID",
            "DIST(ALL)": "DISTANCE",
            "VEHS(ALL)": "VEHS",
            "SPEEDAVGARITH(ALL)": "SPEED",
        }
        np_col_map = {
            "VEHACT(ALL)": "VEHS",
            "TRAVELCOST": "COST"
        }

        # ì»¬ëŸ¼ëª… ë³€ê²½
        df_dir_node.rename(columns=node_col_map, inplace=True)
        df_vttm.rename(columns=vttm_col_map, inplace=True)
        dc.rename(columns=data_col_map, inplace=True)
        np.rename(columns=np_col_map, inplace=True)

        # ------------------------------------------------------------ êµì°¨ë¡œ & êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ ê°€ê³µ

        # df_dir_node ì •ë³´ ë³‘í•©
        node_dir_manager = NodeDirectionManager(config)
        df_node_dir_info = node_dir_manager.fetch_node_dir_info()
        if not df_node_dir_info.empty:
            df_dir_node = df_dir_node.merge(df_node_dir_info, on="MOVEMENT", how="left")
            print("âœ… DIRECTION, APPR_ID ë³‘í•© ì™„ë£Œ")
            
            unmatched = df_dir_node[df_dir_node["MOVEMENT"].isin(df_node_dir_info["MOVEMENT"])]
            # print("âœ… ë³‘í•©ë˜ì§€ ì•Šì€ MOVEMENT ê°’ ì „ì²´ ëª©ë¡:")
            # print(unmatched["MOVEMENT"].unique().tolist())
        else:
            print("â›” ë°©í–¥ ì •ë³´ ë³‘í•© ìŠ¤í‚µ (ë°ì´í„° ì—†ìŒ)")

        # ê³µí†µ ê°€ê³µ
        df_dir_node["STAT_HOUR"] = stat_hour
        df_dir_node["TIMEINT"] = df_dir_node["TIMEINT"].map(timeint_map).fillna(df_dir_node["TIMEINT"])
        df_dir_node = df_dir_node[df_dir_node["NODE_ID"].notna() & (df_dir_node["NODE_ID"] != "")]
        df_dir_node.drop(columns=[col for col in ["SIMRUN"] if col in df_dir_node.columns], inplace=True)

        # êµì°¨ë¡œ / ë°©í–¥ë³„ ë¶„ë¦¬
        df_node = df_dir_node[df_dir_node["MOVEMENT"].apply(lambda x: '@' not in str(x))].copy()
        df_node.rename(columns={"MOVEMENT": "CROSS_ID"}, inplace=True)
        df_dir_node = df_dir_node[df_dir_node["MOVEMENT"].apply(lambda x: '@' in str(x))].copy()
        
        # ì»¬ëŸ¼ ì •ë ¬
        # ê¶Œì—­, ë¶„ì„ëŒ€ìƒì¼ì, ë¶„ì„ëŒ€ìƒì‹œê°„, í‘œì¤€ë…¸ë“œì•„ì´ë””, SAë²ˆí˜¸, ë°©í–¥ê¸°ì¤€ê°’, ëŒ€ê¸°í–‰ë ¬, í†µí–‰ëŸ‰, ì§€ì²´ì‹œê°„(ì´ˆ), ì •ì§€íšŸìˆ˜
        base_cols = ["STAT_HOUR", "TIMEINT", "NODE_ID", "CROSS_ID", "NODE_NAME", "SA_NO", "MOVEMENT", "QLEN", "VEHS", "DELAY", "STOPS"]
        # ì ‘ê·¼ë¡œë°©í–¥(ì‹œê³„ë°©í–¥ê°’), ìš°ì§ì¢Œ(1, 2, 3)
        dir_extra_cols = ["APPR_ID", "DIRECTION"]

        df_node = df_node[[col for col in base_cols if col in df_node.columns]]
        df_node.drop(columns=[col for col in ["CROSS_ID", "NODE_NAME"] if col in df_node.columns], inplace=True)
        df_dir_node = df_dir_node[[col for col in base_cols + dir_extra_cols if col in df_dir_node.columns]]
        
        # ------------------------------------------------------------ ë°©í–¥ë³„ êµì°¨ë¡œ ì¬ê°€ê³µ
        
        # [1] APPR_ID ì—†ëŠ” í–‰ ì œê±°
        df_dir_node = df_dir_node[df_dir_node["APPR_ID"].notna() & (df_dir_node["APPR_ID"] != "")].copy()

        # [2] ìˆ«ì ì»¬ëŸ¼ì„ floatìœ¼ë¡œ ë³€í™˜ (ì—ëŸ¬ ë°©ì§€)
        for col in ["QLEN", "DELAY", "STOPS", "VEHS"]:
            df_dir_node[col] = pd.to_numeric(df_dir_node[col], errors='coerce')

        # [3] ê·¸ë£¹ ê¸°ì¤€ ì •ì˜
        group_cols = ["STAT_HOUR", "TIMEINT", "NODE_ID", "CROSS_ID", "NODE_NAME", "SA_NO", "APPR_ID", "DIRECTION"]

        # [4] QLEN, DELAY, STOPSì€ í‰ê· , VEHSëŠ” í•©ê³„ ì²˜ë¦¬
        df_dir_node = (
            df_dir_node
            .groupby(group_cols, as_index=False)
            .agg({
                "QLEN": "mean",
                "DELAY": "mean",
                "STOPS": "mean",
                "VEHS": "sum"
            })
        )

        # [5] í‰ê·  í•­ëª© ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
        df_dir_node["QLEN"] = df_dir_node["QLEN"].round(2)
        df_dir_node["DELAY"] = df_dir_node["DELAY"].round(2)
        df_dir_node["STOPS"] = df_dir_node["STOPS"].round(2)
        
        # ------------------------------------------------------------ êµ¬ê°„ ê²°ê³¼ê°’ ê°€ê³µ
        
        # êµ¬ê°„ë¶„ì„ì—ì„œ í™œì„±í™”ëœ êµ¬ê°„ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ì‚­ì œ
        df_vttm = df_vttm[df_vttm["ACTIVE"] == str(1)].copy()
        
        df_vttm["STAT_HOUR"] = stat_hour
        
        # í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ ì œê±°
        df_vttm.drop(columns=[col for col in ["SIMRUN", "VEHICLETRAVELTIMEMEASUREMENT", "TIMEINT"] if col in df_vttm.columns], inplace=True)

        # # VTTM_INFO ì¡°íšŒ ë° ë³‘í•©
        vttm_info_manager = VTTMInfoManager(config)
        df_vttm_info = vttm_info_manager.fetch_vttm_info()

        if not df_vttm_info.empty:
            df_vttm = df_vttm.merge(df_vttm_info, on="VTTM_ID", how="left")
            print("âœ… êµ¬ê°„ ë…¸ë“œ ì •ë³´ ë³‘í•© ì™„ë£Œ")
        else:
            print("ğŸ”µ êµ¬ê°„ ë…¸ë“œ ì •ë³´ ë³‘í•© ìŠ¤í‚µ (ë°ì´í„° ì—†ìŒ)")

        # ì»¬ëŸ¼ ì •ë ¬
        # ê¶Œì—­, ë¶„ì„ëŒ€ìƒì¼ì, ë¶„ì„ëŒ€ìƒì‹œê°„, êµ¬ê°„ì•„ì´ë””, ì‹œì êµì°¨ë¡œëª…, ì¢…ì êµì°¨ë¡œëª…, ìƒí•˜í–‰êµ¬ë¶„, ê±°ë¦¬(m), í†µí–‰ëŸ‰, ì‹œê°„(ì´ˆ), SAë²ˆí˜¸, ëŒ€ë¡œëª…, í™œì„±í™”ì—¬ë¶€
        desired_vttm_cols = ["STAT_HOUR", "TIMEINT", "VTTM_ID", "FROM_NODE_NAME", "TO_NODE_NAME", "UPDOWN", "DISTANCE", "VEHS", "TRAVEL_TIME", "SA_NO", "ROAD_NAME", "ACTIVE"]
        df_vttm = df_vttm[[col for col in desired_vttm_cols if col in df_vttm.columns]]
        
        # ------------------------------------------------------------ Data Collection ì»¬ëŸ¼ ì œê±°
        district_code = district_map.get(area)
        
        dc.drop(columns=[c for c in ["DATACOLLECTIONMEASUREMENTEVALUATION:SIMRUN", "TIMEINT"] if c in dc.columns], inplace=True)
        dc["STAT_HOUR"] = stat_hour
        dc["DISTRICT"] = district_code
        
        # ------------------------------------------------------------ Network Performance ì»¬ëŸ¼ ì œê±°
        # DISTRICT, STAT_HOUR, VEHS, COST
        
        np.drop(columns=[c for c in ["VEHICLENETWORKPERFORMANCEMEASUREMENTEVALUATION:SIMRUN", "TIMEINT"] if c in np.columns], inplace=True)
        np["STAT_HOUR"] = stat_hour
        np["DISTRICT"] = district_code
        np.drop(columns=["SIMRUN"], errors="ignore", inplace=True)
        
        # ------------------------------------------------------------ êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ / êµì°¨ë¡œ ê²°ê³¼ê°’ ì—‘ì…€ ì €ì¥
        
        output_dir = os.path.join(target_folder, "results_csv")
        os.makedirs(output_dir, exist_ok=True)

        df_node.to_csv(os.path.join(output_dir, f"{area_name}_{stat_hour}_node.csv"), index=False, encoding="utf-8-sig")
        df_dir_node.to_csv(os.path.join(output_dir, f"{area_name}_{stat_hour}_dir_node.csv"), index=False, encoding="utf-8-sig")
        df_vttm.to_csv(os.path.join(output_dir, f"{area_name}_{stat_hour}_vttm.csv"), index=False, encoding="utf-8-sig")
        dc.to_csv(os.path.join(output_dir, f"{area_name}_{stat_hour}_dc.csv"), index=False, encoding="utf-8-sig")
        np.to_csv(os.path.join(output_dir, f"{area_name}_{stat_hour}_np.csv"), index=False, encoding="utf-8-sig")

        print(f"âœ… CSV ì €ì¥ ì™„ë£Œ â†’ {output_dir}")

        return df_node.copy(), df_dir_node.copy(), df_vttm.copy(), dc.copy(), np.copy()

    # ============================================================================ [ ì €ì¥ ]

    def save_results(self, result, area_name, hour_key):

        df_dir_node, df_node, df_vttm, dc, np = result

        insert_vttm_results_to_db(df_vttm, self.db) # êµ¬ê°„ ê²°ê³¼ê°’ DB INSERT
        insert_node_results_to_db(df_node, self.db) # êµì°¨ë¡œ ê²°ê³¼ê°’ DB INSERT
        insert_node_dir_results_to_db(df_dir_node, self.db) # êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ DB INSERT
        insert_dc_to_db(dc, self.db) # êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ DB INSERT
        insert_np_to_db(np, self.db) # êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ DB INSERT
        
        print(f"âœ… [ DB ì €ì¥ ì™„ë£Œ ] {area_name}-{hour_key} ê²°ê³¼ DB ì €ì¥ ë˜ëŠ” íŒŒì¼ ê¸°ë¡")

    # ============================================================================ [ ì¢…ë£Œ ]

    def close_simulation(self):
        print("âœ… [ ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ ]")
        self.vissim = None

    # ============================================================================ [ ê²°ê³¼ê°’ íŒŒì¼ë“¤ ì „ë¶€ ì‚­ì œ ]

    def cleanup_att_files(self, area):
        import fnmatch
        import os

        target_folder = r"C:\Digital Twin Simulation Network\VISSIM"
        patterns = [
            f"{area}_Node Results_*.att",
            f"{area}_Vehicle Travel Time Results_*.att"
        ]

        deleted = 0
        for pattern in patterns:
            for file in os.listdir(target_folder):
                if fnmatch.fnmatch(file, pattern):
                    try:
                        os.remove(os.path.join(target_folder, file))
                        print(f"ğŸ§¹ [ ì‚­ì œ ì™„ë£Œ ] {file}")
                        deleted += 1
                    except Exception as e:
                        print(f"â›” [ ì‚­ì œ ì‹¤íŒ¨ ] {file} â†’ {e}")

        if deleted == 0:
            print("âš ï¸ ì‚­ì œí•  att íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")









# ============================================================================ [ main ì‹¤í–‰ ]

if __name__ == "__main__":
    
    # ------------------------------------------------------------ ë¡œê·¸ í´ë” ë° íŒŒì¼ëª… ì§€ì •
    
    log_folder = "logs"
    os.makedirs(log_folder, exist_ok=True)

    start_time = datetime.datetime.now()
    log_filename = start_time.strftime("%Y%m%d_%H%M%S_simulation.log")
    log_path = os.path.join(log_folder, log_filename)

    # ------------------------------------------------------------ ë¡œê·¸íŒŒì¼ë¡œ ì¶œë ¥ ë¦¬ë””ë ‰ì…˜
    
    with open(log_path, "w", encoding="utf-8") as log_file, redirect_stdout(log_file):
        print("ğŸŸ¢ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
        print(f"â–¶ï¸ ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

        # ------------------------------------------------------------ ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì½”ë“œ
        
        config = Config()
        db = DatabaseManager(config)
        vissim_manager = VissimSimulationManager(config, db)
        db.fetch_peak_traffic_data()
        area_list = ["gyodong", "gyeongpo", "downtown", "songjung"]
        
        for area in area_list:
            vissim_manager.run_full_simulation(area)

        end_time = datetime.datetime.now()
        duration = end_time - start_time
        print("=" * 60)
        print("ğŸ”´ ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ")
        print(f"â¹ï¸ ì¢…ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ•’ ì´ ì†Œìš” ì‹œê°„: {str(duration).split('.')[0]} (HH:MM:SS)")

    print(f"âœ… ë¡œê·¸ ì €ì¥ ì™„ë£Œ â†’ {log_path}")