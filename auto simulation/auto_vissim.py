import sys
import os
import re
import shutil
import pyodbc
import fnmatch
import datetime
import pywintypes
import pandas as pd
import win32com.client as com
from decimal import Decimal
from dotenv import load_dotenv
from contextlib import redirect_stdout









def set_dpi_awareness():
    try:
        from ctypes import windll
        windll.shcore.SetProcessDpiAwareness(1)
    except ImportError:
        print("ctypes ëª¨ë“ˆì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Python í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”.")
    except AttributeError:
        print("SetProcessDpiAwareness í•¨ìˆ˜ê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” í™˜ê²½ì…ë‹ˆë‹¤. Windows 8.1 ì´ìƒì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.")
    except OSError as os_error:
        print(f"OS ê´€ë ¨ ì˜¤ë¥˜ ë°œìƒ: {os_error}")
    except Exception as e:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
set_dpi_awareness()
sys.path.append(os.path.dirname(os.path.abspath(__file__)))









# ============================================================================ [ í˜„ì¬ ì¼ì‹œ ì„¤ì • ë° ì „ë‚  ì‹œê°„ ê³„ì‚° ]

# í˜„ì¬ ì‹œê°„ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ë¶€ë¶„
current_datetime = datetime.datetime.now()

# >> ì•„ë˜ ë³€ìˆ˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìˆ˜ë™ìœ¼ë¡œ í˜„ì¬ì‹œê°„ì„ ì§€ì •í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. í˜„ì¬ ì‹œê°ì„ ìˆ˜ë™ ì§€ì •í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
current_datetime = datetime.datetime.strptime("2025070209", "%Y%m%d%H")

# ì „ë‚  ë‚ ì§œ ê³„ì‚°
target_date = (current_datetime - datetime.timedelta(days=1)).strftime("%Y%m%d")
peak_hours = ['08', '11', '14', '17']
target_stat_hours = [f"{target_date}{hour}" for hour in peak_hours]  # ["2025070108", "2025070111", "2025070114", "2025070117"]

# ì¡°íšŒëœ ë°ì´í„°ë¥¼ ë‹´ì„ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
traffic_data_08 = []
traffic_data_11 = []
traffic_data_14 = []
traffic_data_17 = []









# ============================================================================ [ ì „ì—­ìƒíƒœì„¤ì • - DBì ‘ì†ì •ë³´ & ë„¤íŠ¸ì›Œí¬ ]

class Config:
    
    def __init__(self):
        load_dotenv(dotenv_path="C:/Digital Twin Simulation Program/.env")
        self.env = os.getenv("FLASK_ENV", "production")
        
        self.db_config = {
            "test": {
                "driver": "Tibero 5 ODBC Driver",
                "server": os.getenv("ENZERO_SERVER"),
                "port": os.getenv("ENZERO_PORT"),
                "db": os.getenv("ENZERO_DB"),
                "uid": os.getenv("ENZERO_UID"),
                "pwd": os.getenv("ENZERO_PWD")
            },
            "prod": {
                "dsn": os.getenv("DSNNAME"),
                "uid": os.getenv("DBUSER"),
                "pwd": os.getenv("DBPWD")
            }
        }

        self.vissim_paths = self._load_vissim_paths()

    # ì•„ë ˆë‚˜, ì†¡ì •ë™, ë„ì‹¬, êµë™ ë„¤íŠ¸ì›Œí¬ ê²½ë¡œ
    
    def _load_vissim_paths(self):
        base_path = r"C:\Digital Twin Simulation Network\VISSIM"
        file_list = [
            "ì•„ë ˆë‚˜.inpx",
            "ì†¡ì •ë™.inpx",
            "ë„ì‹¬(ê°•ë¦‰ì—­).inpx",
            "êµë™ì§€êµ¬.inpx"
        ]
        return {
            os.path.splitext(name)[0]: os.path.join(base_path, name)
            for name in file_list
        }

# ============================================================================ [ DB ì—°ê²° - êµí†µëŸ‰ ì¡°íšŒ ]

class DatabaseManager:
    
    def __init__(self, config: Config):
        self.config = config
        self.conn = self._connect()
        self.cursor = self.conn.cursor() if self.conn else None
        self.columns = [
            "STAT_HOUR", "CROSS_ID", "INFRA_TYPE", "SPECIALDAY", "VPHG", "VPHG", "VS", "LOS",
            "VOL_01", "VOL_02", "VOL_03", "VOL_04", "VOL_05", "VOL_06", "VOL_07", "VOL_08", "VOL_09",
            "VOL_10", "VOL_11", "VOL_12", "VOL_13", "VOL_14", "VOL_15", "VOL_16", "VOL_17", "VOL_18",
            "VOL_19", "VOL_20", "VOL_21", "VOL_22", "VOL_23",
            "WALKER_CNT", "CRASH_CNT", "DELAY_TIME"
        ]
        self.traffic_data_by_hour = {
            "08": [],
            "11": [],
            "14": [],
            "17": []
        }

    def _connect(self):
        try:
            if self.config.env == "test":
                db = self.config.db_config["test"]
                return pyodbc.connect(
                    f"DRIVER={db['driver']};"
                    f"SERVER={db['server']};"
                    f"PORT={db['port']};"
                    f"DB={db['db']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
            else:
                db = self.config.db_config["prod"]
                return pyodbc.connect(
                    f"DSN={db['dsn']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
        except Exception as e:
            print("â›” DB ì—°ê²° ì‹¤íŒ¨:", e)
            return None

    def fetch_peak_traffic_data(self):
        try:
            def convert_row_to_dict(row, columns):
                return {
                    col: float(val) if isinstance(val, Decimal) else val
                    for col, val in zip(columns, row)
                }

            if not self.cursor:
                print(">>> DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return

            formatted_hours = "', '".join(target_stat_hours)
            query = f"""
                SELECT *
                FROM TOMMS.STAT_HOUR_CROSS
                WHERE STAT_HOUR IN ('{formatted_hours}')
                AND INFRA_TYPE = 'SMT'
            """
            self.cursor.execute(query)
            rows = self.cursor.fetchall()
            data_dicts = [convert_row_to_dict(row, self.columns) for row in rows]

            # ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ ì €ì¥
            for row in data_dicts:
                stat_hour = row["STAT_HOUR"]
                suffix = stat_hour[-2:]
                if suffix in self.traffic_data_by_hour:
                    self.traffic_data_by_hour[suffix].append(row)

            print(f"âœ… [ êµí†µëŸ‰ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ ] - ì´ {len(data_dicts)}ê±´")
            for hour in ["08", "11", "14", "17"]:
                print(f"âœ… ì‹œê°„ëŒ€ {hour}: {len(self.traffic_data_by_hour[hour])}ê±´")
                # âœ… ì‹œê°„ëŒ€ 08: 96ê±´
                # âœ… ì‹œê°„ëŒ€ 11: 96ê±´
                # âœ… ì‹œê°„ëŒ€ 14: 96ê±´
                # âœ… ì‹œê°„ëŒ€ 17: 96ê±´

        except Exception as e:
            print("â›” êµí†µëŸ‰ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜:", e)

# ============================================================================ [ DB ì—°ê²° - êµì°¨ë¡œ ë°©í–¥ë³„ movement ì¡°íšŒ ]

class NodeDirectionManager:

    def __init__(self, config: Config):
        self.config = config
        self.conn = self._connect()
        self.cursor = self.conn.cursor() if self.conn else None

    def _connect(self):
        try:
            if self.config.env == "test":
                db = self.config.db_config["test"]
                return pyodbc.connect(
                    f"DRIVER={db['driver']};"
                    f"SERVER={db['server']};"
                    f"PORT={db['port']};"
                    f"DB={db['db']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
            else:
                db = self.config.db_config["prod"]
                return pyodbc.connect(
                    f"DSN={db['dsn']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
        except Exception as e:
            print("â›” DB ì—°ê²° ì‹¤íŒ¨:", e)
            return None

    def fetch_node_dir_info(self):
        if not self.cursor:
            print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        try:
            query = """
                SELECT CROSS_ID, NODE_NAME, APPR_ID, MOVEMENT, DIRECTION
                FROM TOMMS.NODE_DIR_INFO
            """
            self.cursor.execute(query)
            rows = self.cursor.fetchall()

            cleaned_rows = []
            for row in rows:
                cleaned_row = []
                for val in row:
                    if isinstance(val, Decimal):
                        cleaned_row.append(int(val))
                    else:
                        cleaned_row.append(val)
                cleaned_rows.append(tuple(cleaned_row))

            df = pd.DataFrame(cleaned_rows, columns=["CROSS_ID", "NODE_NAME", "APPR_ID", "MOVEMENT", "DIRECTION"])
            
            print(f"âœ… NODE_DIR_INFO ì¡°íšŒ ì™„ë£Œ - {len(df)}ê±´")
            return df

        except Exception as e:
            print("â›” NODE_DIR_INFO ì¡°íšŒ ì‹¤íŒ¨:", e)
            return pd.DataFrame()

# ============================================================================ [ DB ì—°ê²° - êµ¬ê°„ ì •ë³´ ì¡°íšŒ ]

class VTTMInfoManager:

    def __init__(self, config: Config):
        self.config = config
        self.conn = self._connect()
        self.cursor = self.conn.cursor() if self.conn else None

    def _connect(self):
        try:
            if self.config.env == "test":
                db = self.config.db_config["test"]
                return pyodbc.connect(
                    f"DRIVER={db['driver']};"
                    f"SERVER={db['server']};"
                    f"PORT={db['port']};"
                    f"DB={db['db']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
            else:
                db = self.config.db_config["prod"]
                return pyodbc.connect(
                    f"DSN={db['dsn']};"
                    f"UID={db['uid']};"
                    f"PWD={db['pwd']};"
                )
        except Exception as e:
            print("â›” DB ì—°ê²° ì‹¤íŒ¨:", e)
            return None

    def fetch_vttm_info(self):
        if not self.cursor:
            print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        try:
            query = """
                SELECT VTTM_ID, FROM_NODE_NAME, TO_NODE_NAME
                FROM TOMMS.VTTM_INFO
            """
            self.cursor.execute(query)
            rows = self.cursor.fetchall()

            cleaned_rows = []
            for row in rows:
                cleaned_row = []
                for val in row:
                    if isinstance(val, Decimal):
                        cleaned_row.append(int(val))
                    else:
                        cleaned_row.append(val)
                cleaned_rows.append(tuple(cleaned_row))

            df = pd.DataFrame(cleaned_rows, columns=["VTTM_ID", "FROM_NODE_NAME", "TO_NODE_NAME"])
            print(f"âœ… VTTM_INFO ì¡°íšŒ ì™„ë£Œ - {len(df)}ê±´")
            return df

        except Exception as e:
            print("â›” VTTM_INFO ì¡°íšŒ ì‹¤íŒ¨:", e)
            return pd.DataFrame()









# ============================================================================ [ êµ¬ê°„ ê²°ê³¼ê°’ DB INSERT ]

# ---------------------------------------------------------------------------- [ í†µí–‰ë¹„ìš© ì¶”ê°€ í•„ìš” ]

def insert_vttm_results_to_db(df_vttm, db_manager):
    
    if db_manager.cursor is None:
        print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    insert_query = """
        INSERT INTO VTTM_RESULT (
            DISTRICT, STAT_HOUR, VTTM_ID,
            FROM_NODE_NAME, TO_NODE_NAME, UPDOWN,
            DISTANCE, VEHS, TRAVEL_TIME,
            SA_NO, ROAD_NAME, ACTIVE
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """

    # NaNì„ Noneìœ¼ë¡œ ëŒ€ì²´, íƒ€ì… í˜•ë³€í™˜
    def clean_value(val, target_type):
        if pd.isna(val):
            return None
        try:
            if target_type == "int":
                return int(val)
            elif target_type == "float":
                return float(val)
            elif target_type == "str":
                return str(val)
        except:
            return None

    insert_data = []
    for _, row in df_vttm.iterrows():
        insert_data.append((
            clean_value(row.get("DISTRICT"), "int"),
            clean_value(row.get("STAT_HOUR"), "str"),
            clean_value(row.get("VTTM_ID"), "str"),
            clean_value(row.get("FROM_NODE_NAME"), "str"),
            clean_value(row.get("TO_NODE_NAME"), "str"),
            clean_value(row.get("UPDOWN"), "int"),
            clean_value(row.get("DISTANCE"), "float"),
            clean_value(row.get("VEHS"), "int"),
            clean_value(row.get("TRAVEL_TIME"), "float"),
            clean_value(row.get("SA_NO"), "str"),
            clean_value(row.get("ROAD_NAME"), "str"),
            clean_value(row.get("ACTIVE"), "int")
        ))

    try:
        db_manager.cursor.executemany(insert_query, insert_data)
        db_manager.conn.commit()
        print(f"âœ… VTTM_RESULTì— {len(insert_data)}ê±´ ì‚½ì… ì™„ë£Œ")
    except Exception as e:
        print("â›” DB ì‚½ì… ì¤‘ ì˜¤ë¥˜:", e)
        db_manager.conn.rollback()

# ============================================================================ [ êµì°¨ë¡œ ê²°ê³¼ê°’ DB INSERT ]

def insert_node_results_to_db(df_node: pd.DataFrame, db_manager):
    
    if db_manager.cursor is None:
        print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    insert_query = """
        INSERT INTO NODE_RESULT (
            DISTRICT, STAT_HOUR, TIMEINT,
            NODE_ID, SA_NO,
            QLEN, VEHS, DELAY, STOPS
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    """

    def clean_value(val, target_type):
        if pd.isna(val):
            return None
        try:
            if target_type == "int":
                return int(val)
            elif target_type == "float":
                return float(val)
            elif target_type == "str":
                return str(val)
        except:
            return None

    insert_data = []
    for _, row in df_node.iterrows():
        insert_data.append((
            clean_value(row.get("DISTRICT"), "int"),
            clean_value(row.get("STAT_HOUR"), "str"),
            clean_value(row.get("TIMEINT"), "str"),
            clean_value(row.get("NODE_ID"), "str"),
            clean_value(row.get("SA_NO"), "str"),
            clean_value(row.get("QLEN"), "float"),
            clean_value(row.get("VEHS"), "int"),
            clean_value(row.get("DELAY"), "float"),
            clean_value(row.get("STOPS"), "float")
        ))

    try:
        db_manager.cursor.executemany(insert_query, insert_data)
        db_manager.conn.commit()
        print(f"âœ… NODE_RESULTì— {len(insert_data)}ê±´ ì‚½ì… ì™„ë£Œ")
    except Exception as e:
        print("â›” NODE_RESULT ì‚½ì… ì˜¤ë¥˜:", e)
        db_manager.conn.rollback()

# ============================================================================ [ êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ DB INSERT ]

def insert_node_dir_results_to_db(df_dir_node: pd.DataFrame, db_manager):
    
    if db_manager.cursor is None:
        print("â›” DB ì»¤ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    insert_query = """
        INSERT INTO NODE_DIR_RESULT (
            DISTRICT, STAT_HOUR, TIMEINT,
            NODE_ID, CROSS_ID, NODE_NAME,
            SA_NO, APPR_ID, DIRECTION,
            QLEN, VEHS, DELAY, STOPS
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """

    def clean_value(val, target_type):
        if pd.isna(val):
            return None
        try:
            if target_type == "int":
                return int(val)
            elif target_type == "float":
                return float(val)
            elif target_type == "str":
                return str(val)
        except:
            return None

    insert_data = []
    for _, row in df_dir_node.iterrows():
        insert_data.append((
            clean_value(row.get("DISTRICT"), "int"),
            clean_value(row.get("STAT_HOUR"), "str"),
            clean_value(row.get("TIMEINT"), "str"),
            clean_value(row.get("NODE_ID"), "str"),
            clean_value(row.get("CROSS_ID"), "int"),
            clean_value(row.get("NODE_NAME"), "str"),
            clean_value(row.get("SA_NO"), "str"),
            clean_value(row.get("APPR_ID"), "int"),
            clean_value(row.get("DIRECTION"), "int"),
            clean_value(row.get("QLEN"), "float"),
            clean_value(row.get("VEHS"), "int"),
            clean_value(row.get("DELAY"), "float"),
            clean_value(row.get("STOPS"), "float")
        ))

    try:
        db_manager.cursor.executemany(insert_query, insert_data)
        db_manager.conn.commit()
        print(f"âœ… NODE_DIR_RESULTì— {len(insert_data)}ê±´ ì‚½ì… ì™„ë£Œ")
    except Exception as e:
        print("â›” NODE_DIR_RESULT ì‚½ì… ì˜¤ë¥˜:", e)
        db_manager.conn.rollback()









# ============================================================================ [ ì‹œë®¬ë ˆì´ì…˜ ì»¨íŠ¸ë¡¤ëŸ¬ ]

class VissimSimulationManager:
    
    def __init__(self, config: Config, db_manager: DatabaseManager):
        self.vissim = None
        self.paths = config.vissim_paths
        self.db = db_manager

    # ============================================================================ [ ì—°ê³„ - ì‹¤í–‰ - ì¶”ì¶œ - ì €ì¥ - ì¢…ë£Œ ]

    def run_full_simulation(self, area):
        global target_stat_hours

        district_map = {
            "êµë™ì§€êµ¬": 1,
            "ì†¡ì •ë™": 2,
            "ë„ì‹¬(ê°•ë¦‰ì—­)": 3,
            "ì•„ë ˆë‚˜": 4
        }

        print(f"ğŸ”µ vissim ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ê±´ë„¤ë°›ì€ ë¶„ì„ëŒ€ìƒ ì¼ì‹œ : {target_date}")
        path = self.paths.get(area)

        if not path or not os.path.isfile(path):
            print(f"â›” [ ê²½ê³  ] {area} íŒŒì¼ ì—†ìŒ: {path}")
            return

        # VISSIM ê°ì²´ ìƒì„± (í•œ ë²ˆë§Œ)
        try:
            self.vissim = com.Dispatch("Vissim.Vissim.22")
            print("ğŸ”µ VISSIM COM ê°ì²´ ìƒì„±")
        except pywintypes.com_error:
            print("â›” [ ì˜¤ë¥˜ ] VISSIM ê°ì²´ ìƒì„± ì‹¤íŒ¨")
            self.vissim = None
            return

        # ------------------------------------------------------------ ë°˜ë³µëœ ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„
        for idx, (hour_key, traffic_list) in enumerate(db.traffic_data_by_hour.items()):
            try:
                idx = peak_hours.index(hour_key)
                full_stat_hour = target_stat_hours[idx]
            except ValueError:
                print(f"â›” [ ì˜¤ë¥˜ ] ì‹œê°„ëŒ€ {hour_key}ëŠ” peak_hoursì— ì—†ìŠµë‹ˆë‹¤.")
                continue

            print(f"ğŸ”µ [ {area} ] ( {full_stat_hour} ) ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ===")

            # [1] ì´ì „ ê²°ê³¼ ì‚­ì œ
            self.cleanup_att_files(area)

            # [2] ë„¤íŠ¸ì›Œí¬ íŒŒì¼ ë‹¤ì‹œ ë¡œë“œ (ìƒíƒœ ì´ˆê¸°í™”)
            try:
                self.vissim.LoadNet(path, False)
                print(f"ğŸ” [ ë„¤íŠ¸ì›Œí¬ ì¬ë¡œë“œ ì™„ë£Œ ] {area} â†’ {path}")
            except pywintypes.com_error:
                print(f"â›” [ ì˜¤ë¥˜ ] ë„¤íŠ¸ì›Œí¬ ì¬ë¡œë“œ ì‹¤íŒ¨: {path}")
                continue

            # [3] êµí†µëŸ‰ ì—°ê³„ â†’ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ â†’ ê²°ê³¼ ì¶”ì¶œ
            self.apply_traffic_data(traffic_list)
            self.run_simulation()
            df_node, df_dir_node, df_vttm = self.extract_results(stat_hour=full_stat_hour, area_name=area)

            # [4] ì§€ì—­ì½”ë“œ ë¶€ì—¬
            district_code = district_map.get(area)
            df_node["DISTRICT"] = district_code
            df_dir_node["DISTRICT"] = district_code
            df_vttm["DISTRICT"] = district_code

            # [5] ê²°ê³¼ DB ì €ì¥
            self.save_results((df_dir_node, df_node, df_vttm), area, hour_key)

            # [6] ê²°ê³¼ íŒŒì¼ ì‚­ì œ
            self.cleanup_att_files(area)

        # ------------------------------------------------------------ ì¢…ë£Œ
        self.close_simulation()

    # ============================================================================ [ ì—°ê³„ - vehicle input / static route ]

    def apply_traffic_data(self, traffic_list):
        
        print(f"ğŸ”µ [ êµí†µëŸ‰ ì…ë ¥ ì‹œì‘ ] ì´ {len(traffic_list)}ê±´")

        for idx, row in enumerate(traffic_list, 1):
            stat_hour = row.get("STAT_HOUR")
            cross_id = row.get("CROSS_ID")

            # VOL_xx ì¤‘ Noneì´ ì•„ë‹Œ ê°’ë§Œ ì¶”ì¶œ
            volume_data = {
                key.replace("VOL_", ""): int(value)
                for key, value in row.items()
                if key.startswith("VOL_") and value is not None
            }

            # ------------------------------------------------------------ [ vehicle input êµí†µëŸ‰ ì…ë ¥ ]
            
            num_decisions = self.vissim.Net.VehicleRoutingDecisionsStatic.count
            vehicle_input_nos = self.vissim.Net.VehicleInputs.GetMultiAttValues('No')
            vehicle_input_node_ids = self.vissim.Net.VehicleInputs.GetMultiAttValues('Node_ID')
            vehicle_input_link_ids = self.vissim.Net.VehicleInputs.GetMultiAttValues('Link_ID')
            
            grouped_data_list = []

            for no, node_id, link_id in zip(vehicle_input_nos, vehicle_input_node_ids, vehicle_input_link_ids):
                if node_id[1] is None or link_id[1] is None:  # node_idì™€ link_idì— Noneì´ ìˆìœ¼ë©´ ì œì™¸
                    continue

                # CROSS_IDì™€ node_idê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if str(cross_id) != str(node_id[1]):
                    continue

                # VOL_xxì—ì„œ xx == link_id
                vol_key = f"{int(link_id[1]):02d}"  # ì˜ˆ: 4 â†’ "04"
                vi_vol = volume_data.get(vol_key)

                if vi_vol is None:
                    continue  # í•´ë‹¹ ë°©í–¥ ë°ì´í„° ì—†ìŒ

                print(f"[ Vehicle Input ] (InputNo = {no[1]}) (NodeID = {node_id[1]}) (LinkID = {link_id[1]}) (Volume = {vi_vol})")

                # êµí†µëŸ‰ ì…ë ¥
                vi = self.vissim.Net.VehicleInputs.ItemByKey(no[1])
                vi.SetAttValue('Volume(1)', vi_vol)
                vi.SetAttValue('Volume(2)', vi_vol)
                vi.SetAttValue('Volume(3)', vi_vol)
                vi.SetAttValue('Volume(4)', vi_vol)
                vi.SetAttValue('Volume(5)', vi_vol)
            
            # ------------------------------------------------------------ [ static route êµí†µëŸ‰ ì…ë ¥ ]
            
            vrds = self.vissim.Net.VehicleRoutingDecisionsStatic
            num_decisions = self.vissim.Net.VehicleRoutingDecisionsStatic.Count
            
            for i in range(1, num_decisions + 1):
                if vrds.ItemKeyExists(i):
                    decision = vrds.ItemByKey(i)

                    for route in decision.VehRoutSta.GetAll():
                        sr_node_id = route.AttValue('VehRoutDec\\Node_ID')
                        sr_turn_id = route.AttValue('Turn_ID')
                        
                        # ì¡°ê±´: ë‘˜ ë‹¤ Noneì´ ì•„ë‹ˆì–´ì•¼ í•¨
                        if sr_node_id is None or sr_turn_id is None:
                            continue

                        # CROSS_IDì™€ ë§¤ì¹­
                        if str(cross_id) != str(sr_node_id):
                            continue

                        # Turn_IDì— í•´ë‹¹í•˜ëŠ” vol key ìƒì„± â†’ ex: 3 â†’ "03"
                        vol_key = f"{int(sr_turn_id):02d}"
                        sr_vol = volume_data.get(vol_key)

                        if sr_vol is None:
                            continue  # í•´ë‹¹ ë°©í–¥ì— ëŒ€í•´ êµí†µëŸ‰ ì—†ìŒ

                        print(f"[ Static Route ] (NodeID = {sr_node_id}) (TurnID = {sr_turn_id}) (Volume= {sr_vol})")
                        
                        route.SetAttValue("RelFlow(1)", sr_vol)
                        route.SetAttValue("RelFlow(2)", sr_vol)
                        route.SetAttValue("RelFlow(3)", sr_vol)
                        route.SetAttValue("RelFlow(4)", sr_vol)
                        route.SetAttValue("RelFlow(5)", sr_vol)

    # ============================================================================ [ ì‹¤í–‰ - simulation run ]

    def run_simulation(self):
        self.vissim.Graphics.CurrentNetworkWindow.SetAttValue("QuickMode", 1)
        self.vissim.Simulation.SetAttValue('UseMaxSimSpeed', True)
        self.vissim.Simulation.RunContinuous()

    # ============================================================================ [ ì¶”ì¶œ - node results / vehicle input ]

    def extract_results(self, stat_hour: str, area_name: str):
        
        print(f"ğŸ”µ ë¶„ì„ëŒ€ìƒì¼ì‹œ [ {stat_hour} ] ë¶„ì„ëŒ€ìƒì§€ì—­ [ {area_name} ]") # 2025070108, 2025070111

        target_folder = r"C:\Digital Twin Simulation Network\VISSIM"
        results = {}

        # ------------------------------------------------------------ ì‚­ì œ ëŒ€ìƒ ì œê±° (.results, .err, .lock ë“±)
        
        for file in os.listdir(target_folder):
            full_path = os.path.join(target_folder, file)

            if file.endswith(".err") or file.endswith(".lock"):
                try:
                    os.remove(full_path)
                    print(f"âœ… [ íŒŒì¼ì‚­ì œ ì™„ë£Œ ] : {file}")
                except Exception as e:
                    print(f"â›” [ íŒŒì¼ì‚­ì œ ì‹¤íŒ¨ ]: {file} â†’ {e}")

            elif file.endswith(".results") and os.path.isdir(full_path):
                try:
                    shutil.rmtree(full_path)
                    print(f"âœ… [ í´ë”ì‚­ì œ ì™„ë£Œ ] : {file}")
                except Exception as e:
                    print(f"â›” [ í´ë”ì‚­ì œ ì‹¤íŒ¨ ]: {file} â†’ {e}")

        # ------------------------------------------------------------ íŒŒì¼ ì°¾ê¸°

        def find_latest_index(base_name, result_type):
            pattern = re.compile(rf"{re.escape(base_name)}_{re.escape(result_type)}_(\d+)\.att")
            max_idx = 0
            for file in os.listdir(target_folder):
                match = pattern.match(file)
                if match:
                    idx = int(match.group(1))
                    max_idx = max(max_idx, idx)
            return f"{max_idx:03d}" if max_idx > 0 else None

        # ------------------------------------------------------------ ê²°ê³¼ê°’ dfë¡œ í• ë‹¹í•˜ê¸°

        def read_att_file(path):
            if not os.path.exists(path):
                print(f"â›” íŒŒì¼ ì—†ìŒ: {path}")
                return pd.DataFrame()

            encodings = ["utf-8-sig", "utf-16", "cp949", "utf-8"]
            for enc in encodings:
                try:
                    with open(path, "r", encoding=enc, errors="strict") as f:
                        lines = f.read().splitlines()
                    break
                except (UnicodeDecodeError, UnicodeError):
                    continue
            else:
                print(f"â›” ì¸ì½”ë”© ì‹¤íŒ¨: {path}")
                return pd.DataFrame()

            dollar_lines = [i for i, line in enumerate(lines) if "$" in line]
            if len(dollar_lines) < 2:
                print(f"â›” í¬ë§· ì´ìƒ: {path}")
                return pd.DataFrame()

            header_idx = dollar_lines[1]
            columns = lines[header_idx].replace('$MOVEMENTEVALUATION:', '').replace('$VEHICLETRAVELTIMEMEASUREMENTEVALUATION:', '').strip().split(';')
            data_lines = lines[header_idx + 1:]

            rows = []
            for line in data_lines:
                if not line.strip():
                    continue
                values = line.strip().split(';')
                values = values[:len(columns)] + [''] * (len(columns) - len(values))
                rows.append(dict(zip(columns, values)))

            df = pd.DataFrame(rows)

            # ì¸ì½”ë”© ê¹¨ì§„ ì—´ ìë™ ë³µêµ¬ ì‹œë„ (í•œê¸€ í¬í•¨ ì¶”ì • ì—´ ëŒ€ìƒ)
            for col in df.columns:
                try:
                    if df[col].str.contains("[ê°€-í£]").any():
                        continue  # ì´ë¯¸ í•œê¸€ ì •ìƒ
                    df[col] = df[col].apply(lambda x: x.encode('latin1').decode('cp949') if isinstance(x, str) else x)
                except Exception:
                    continue

            return df

        # ------------------------------------------------------------ ê° êµ¬ì—­ ê²°ê³¼ê°’ ì²˜ë¦¬

        latest_index = find_latest_index(area_name, "Node Results")
        if not latest_index:
            print(f"â›” {area_name}: ì‹œë®¬ë ˆì´ì…˜ íŒŒì¼ ì—†ìŒ")
            return {}

        # íŒŒì¼ ê²½ë¡œ ì •ì˜
        node_file = os.path.join(target_folder, f"{area_name}_Node Results_{latest_index}.att")
        vttm_file = os.path.join(target_folder, f"{area_name}_Vehicle Travel Time Results_{latest_index}.att")

        # íŒŒì¼ ì½ê¸°
        df_dir_node = read_att_file(node_file)
        df_vttm = read_att_file(vttm_file)

        print(f"âœ… {area_name} - Node Results ({df_dir_node.shape[0]}í–‰)")
        print(f"âœ… {area_name} - Travel Time Results ({df_vttm.shape[0]}í–‰)")

        # ì»¬ëŸ¼ëª… ë§¤í•‘
        timeint_map = {
            '600-1500': '00-15',
            '1500-2400': '15-30',
            '2400-3300': '30-45',
            '3300-4200': '45-00',
        }
        node_col_map = {
            "VEHS(ALL)": "VEHS",
            "VEHDELAY(ALL)": "DELAY",
            "STOPS(ALL)": "STOPS",
            "MOVEMENT\\NODE\\NODE_ID": "NODE_ID",
            "MOVEMENT\\NODE\\SA": "SA_NO"
        }
        vttm_col_map = {
            "VEHICLETRAVELTIMEMEASUREMENT\\NAME": "VTTM_ID",
            "VEHS(ALL)": "VEHS",
            "TRAVTM(ALL)": "TRAVEL_TIME",
            "DISTTRAV(ALL)": "DISTANCE",
            "VEHICLETRAVELTIMEMEASUREMENT\\LINKS_ID": "LINK_ID",
            "VEHICLETRAVELTIMEMEASUREMENT\\UPDOWN": "UPDOWN",
            "VEHICLETRAVELTIMEMEASUREMENT\\SA": "SA_NO",
            "VEHICLETRAVELTIMEMEASUREMENT\\ROAD_NAME": "ROAD_NAME",
            "VEHICLETRAVELTIMEMEASUREMENT\\ACTIVE": "ACTIVE"
        }

        # ì»¬ëŸ¼ëª… ë³€ê²½
        df_dir_node.rename(columns=node_col_map, inplace=True)
        df_vttm.rename(columns=vttm_col_map, inplace=True)

        # ------------------------------------------------------------ êµì°¨ë¡œ & êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ ê°€ê³µ

        # df_dir_node ì •ë³´ ë³‘í•©
        node_dir_manager = NodeDirectionManager(config)
        df_node_dir_info = node_dir_manager.fetch_node_dir_info()
        if not df_node_dir_info.empty:
            df_dir_node = df_dir_node.merge(df_node_dir_info, on="MOVEMENT", how="left")
            print("âœ… DIRECTION, APPR_ID ë³‘í•© ì™„ë£Œ")
            
            unmatched = df_dir_node[~df_dir_node["MOVEMENT"].isin(df_node_dir_info["MOVEMENT"])]
            print("âœ… ë³‘í•©ë˜ì§€ ì•Šì€ MOVEMENT ê°’ ì „ì²´ ëª©ë¡:")
            print(unmatched["MOVEMENT"].unique().tolist())
        else:
            print("â›” ë°©í–¥ ì •ë³´ ë³‘í•© ìŠ¤í‚µ (ë°ì´í„° ì—†ìŒ)")

        # ê³µí†µ ê°€ê³µ
        df_dir_node["STAT_HOUR"] = stat_hour
        df_dir_node["TIMEINT"] = df_dir_node["TIMEINT"].map(timeint_map).fillna(df_dir_node["TIMEINT"])
        df_dir_node["DISTRICT"] = area_name
        df_dir_node = df_dir_node[df_dir_node["NODE_ID"].notna() & (df_dir_node["NODE_ID"] != "")]
        df_dir_node.drop(columns=[col for col in ["SIMRUN"] if col in df_dir_node.columns], inplace=True)

        # êµì°¨ë¡œ / ë°©í–¥ë³„ ë¶„ë¦¬
        df_node = df_dir_node[df_dir_node["MOVEMENT"].apply(lambda x: '@' not in str(x))].copy()
        df_node.rename(columns={"MOVEMENT": "CROSS_ID"}, inplace=True)
        df_dir_node = df_dir_node[df_dir_node["MOVEMENT"].apply(lambda x: '@' in str(x))].copy()
        
        # ì»¬ëŸ¼ ì •ë ¬
        # ê¶Œì—­, ë¶„ì„ëŒ€ìƒì¼ì, ë¶„ì„ëŒ€ìƒì‹œê°„, í‘œì¤€ë…¸ë“œì•„ì´ë””, SAë²ˆí˜¸, ë°©í–¥ê¸°ì¤€ê°’, ëŒ€ê¸°í–‰ë ¬, í†µí–‰ëŸ‰, ì§€ì²´ì‹œê°„(ì´ˆ), ì •ì§€íšŸìˆ˜
        base_cols = ["DISTRICT", "STAT_HOUR", "TIMEINT", "NODE_ID", "CROSS_ID", "NODE_NAME", "SA_NO", "MOVEMENT", "QLEN", "VEHS", "DELAY", "STOPS"]
        # ì ‘ê·¼ë¡œë°©í–¥(ì‹œê³„ë°©í–¥ê°’), ìš°ì§ì¢Œ(1, 2, 3)
        dir_extra_cols = ["APPR_ID", "DIRECTION"]

        df_node = df_node[[col for col in base_cols if col in df_node.columns]]
        df_node.drop(columns=[col for col in ["CROSS_ID", "NODE_NAME"] if col in df_node.columns], inplace=True)
        df_dir_node = df_dir_node[[col for col in base_cols + dir_extra_cols if col in df_dir_node.columns]]
        
        # ------------------------------------------------------------ ë°©í–¥ë³„ êµì°¨ë¡œ ì¬ê°€ê³µ
        
        # [1] APPR_ID ì—†ëŠ” í–‰ ì œê±°
        df_dir_node = df_dir_node[df_dir_node["APPR_ID"].notna() & (df_dir_node["APPR_ID"] != "")].copy()

        # [2] ìˆ«ì ì»¬ëŸ¼ì„ floatìœ¼ë¡œ ë³€í™˜ (ì—ëŸ¬ ë°©ì§€)
        for col in ["QLEN", "DELAY", "STOPS", "VEHS"]:
            df_dir_node[col] = pd.to_numeric(df_dir_node[col], errors='coerce')

        # [3] ê·¸ë£¹ ê¸°ì¤€ ì •ì˜
        group_cols = ["DISTRICT", "STAT_HOUR", "TIMEINT", "NODE_ID", "CROSS_ID", "NODE_NAME", "SA_NO", "APPR_ID", "DIRECTION"]

        # [4] QLEN, DELAY, STOPSì€ í‰ê· , VEHSëŠ” í•©ê³„ ì²˜ë¦¬
        df_dir_node = (
            df_dir_node
            .groupby(group_cols, as_index=False)
            .agg({
                "QLEN": "mean",
                "DELAY": "mean",
                "STOPS": "mean",
                "VEHS": "sum"
            })
        )

        # [5] í‰ê·  í•­ëª© ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
        df_dir_node["QLEN"] = df_dir_node["QLEN"].round(2)
        df_dir_node["DELAY"] = df_dir_node["DELAY"].round(2)
        df_dir_node["STOPS"] = df_dir_node["STOPS"].round(2)

        # [6] MOVEMENT ì»¬ëŸ¼ ì œê±° (ì¡´ì¬ ì‹œ)
        if "MOVEMENT" in df_dir_node.columns:
            df_dir_node.drop(columns=["MOVEMENT"], inplace=True)
        
        # ------------------------------------------------------------ êµ¬ê°„ ê²°ê³¼ê°’ ê°€ê³µ
        
        # êµ¬ê°„ë¶„ì„ì—ì„œ í™œì„±í™”ëœ êµ¬ê°„ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ì‚­ì œ
        df_vttm = df_vttm[df_vttm["ACTIVE"] == str(1)].copy()
        
        df_vttm["STAT_HOUR"] = stat_hour
        df_vttm["DISTRICT"] = area_name
        
        # í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ ì œê±°
        df_vttm.drop(columns=[col for col in ["SIMRUN", "VEHICLETRAVELTIMEMEASUREMENT", "TIMEINT"] if col in df_vttm.columns], inplace=True)

        # # VTTM_INFO ì¡°íšŒ ë° ë³‘í•©
        vttm_info_manager = VTTMInfoManager(config)
        df_vttm_info = vttm_info_manager.fetch_vttm_info()

        if not df_vttm_info.empty:
            df_vttm = df_vttm.merge(df_vttm_info, on="VTTM_ID", how="left")
            print("ğŸ”µ êµ¬ê°„ ë…¸ë“œ ì •ë³´ ë³‘í•© ì™„ë£Œ")
        else:
            print("ğŸ”µ êµ¬ê°„ ë…¸ë“œ ì •ë³´ ë³‘í•© ìŠ¤í‚µ (ë°ì´í„° ì—†ìŒ)")

        # ì»¬ëŸ¼ ì •ë ¬
        # ê¶Œì—­, ë¶„ì„ëŒ€ìƒì¼ì, ë¶„ì„ëŒ€ìƒì‹œê°„, êµ¬ê°„ì•„ì´ë””, ì‹œì êµì°¨ë¡œëª…, ì¢…ì êµì°¨ë¡œëª…, ìƒí•˜í–‰êµ¬ë¶„, ê±°ë¦¬(m), í†µí–‰ëŸ‰, ì‹œê°„(ì´ˆ), SAë²ˆí˜¸, ëŒ€ë¡œëª…, í™œì„±í™”ì—¬ë¶€
        desired_vttm_cols = ["DISTRICT", "STAT_HOUR", "TIMEINT", "VTTM_ID", "FROM_NODE_NAME", "TO_NODE_NAME", "UPDOWN", "DISTANCE", "VEHS", "TRAVEL_TIME", "SA_NO", "ROAD_NAME", "ACTIVE"]
        df_vttm = df_vttm[[col for col in desired_vttm_cols if col in df_vttm.columns]]
        
        # ------------------------------------------------------------ êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ / êµì°¨ë¡œ ê²°ê³¼ê°’ ì—‘ì…€ ì €ì¥

        return df_node.copy(), df_dir_node.copy(), df_vttm.copy()

    # ============================================================================ [ ì €ì¥ ]

    def save_results(self, result, area_name, hour_key):

        df_dir_node, df_node, df_vttm = result

        insert_vttm_results_to_db(df_vttm, self.db) # êµ¬ê°„ ê²°ê³¼ê°’ DB INSERT
        insert_node_results_to_db(df_node, self.db) # êµì°¨ë¡œ ê²°ê³¼ê°’ DB INSERT
        insert_node_dir_results_to_db(df_dir_node, self.db) # êµì°¨ë¡œ ë°©í–¥ë³„ ê²°ê³¼ê°’ DB INSERT
        
        print(f"âœ… [ DB ì €ì¥ ì™„ë£Œ ] {area_name}-{hour_key} ê²°ê³¼ DB ì €ì¥ ë˜ëŠ” íŒŒì¼ ê¸°ë¡")

    # ============================================================================ [ ì¢…ë£Œ ]

    def close_simulation(self):
        print("âœ… [ ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ ]")
        self.vissim = None

    # ============================================================================ [ ê²°ê³¼ê°’ íŒŒì¼ë“¤ ì „ë¶€ ì‚­ì œ ]

    def cleanup_att_files(self, area):
        import fnmatch
        import os

        target_folder = r"C:\Digital Twin Simulation Network\VISSIM"
        patterns = [
            f"{area}_Node Results_*.att",
            f"{area}_Vehicle Travel Time Results_*.att"
        ]

        deleted = 0
        for pattern in patterns:
            for file in os.listdir(target_folder):
                if fnmatch.fnmatch(file, pattern):
                    try:
                        os.remove(os.path.join(target_folder, file))
                        print(f"ğŸ§¹ [ ì‚­ì œ ì™„ë£Œ ] {file}")
                        deleted += 1
                    except Exception as e:
                        print(f"â›” [ ì‚­ì œ ì‹¤íŒ¨ ] {file} â†’ {e}")

        if deleted == 0:
            print("âš ï¸ ì‚­ì œí•  att íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")









# ============================================================================ [ main ì‹¤í–‰ ]

if __name__ == "__main__":
    
    # ------------------------------------------------------------ ë¡œê·¸ í´ë” ë° íŒŒì¼ëª… ì§€ì •
    
    log_folder = "logs"
    os.makedirs(log_folder, exist_ok=True)

    start_time = datetime.datetime.now()
    log_filename = start_time.strftime("%Y%m%d_%H%M%S_simulation.log")
    log_path = os.path.join(log_folder, log_filename)

    # ------------------------------------------------------------ ë¡œê·¸íŒŒì¼ë¡œ ì¶œë ¥ ë¦¬ë””ë ‰ì…˜
    
    with open(log_path, "w", encoding="utf-8") as log_file, redirect_stdout(log_file):
        print("ğŸŸ¢ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
        print(f"â–¶ï¸ ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

        # ------------------------------------------------------------ ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì½”ë“œ
        
        config = Config()
        db = DatabaseManager(config)
        vissim_manager = VissimSimulationManager(config, db)

        db.fetch_peak_traffic_data()

        area_list = ["ì•„ë ˆë‚˜", "ì†¡ì •ë™", "ë„ì‹¬(ê°•ë¦‰ì—­)", "êµë™ì§€êµ¬"]
        for area in area_list:
            vissim_manager.run_full_simulation(area)

        end_time = datetime.datetime.now()
        duration = end_time - start_time
        print("=" * 60)
        print("ğŸ”´ ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ")
        print(f"â¹ï¸ ì¢…ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ•’ ì´ ì†Œìš” ì‹œê°„: {str(duration).split('.')[0]} (HH:MM:SS)")

    print(f"âœ… ë¡œê·¸ ì €ì¥ ì™„ë£Œ â†’ {log_path}")